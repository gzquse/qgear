#!/bin/bash 
#SBATCH  -C gpu -N 1 -A nintern
# SBATCH --ntasks-per-node=4
#SBATCH  --time=28:00 -q debug
# SBATCH --time 23:58:00  -q regular 
#SBATCH --output=out/%j.out
#SBATCH  --licenses=scratch
# - - - E N D    O F    SLURM    C O M M A N D S

set -u ;  # exit  if you try to use an uninitialized variable

module load cudatoolkit
export MPICH_GPU_SUPPORT_ENABLED=1

expN=${1:-cg24q}
trg=${2:-adj-gpu}
shots=${3:-10240}
if [ "$trg" == "par-cpu" ]; then
    backend='qiskit-cpu'
elif [ "$trg" == "par-gpu" ]; then
     backend="nvidia-mqpu"  # all 4 GPUs in parallel
elif [ "$trg" == "adj-gpu" ]; then
    backend="nvidia-mgpu"
fi

#env
echo S:  expN=$expN  backend=$backend    expN=$expN   user=$USER
N=${SLURM_NNODES:-1}
T=${SLURM_NTASKS_PER_NODE:-1}
G=$(( T * N ))

echo S: head:`hostname` N=$N  T=$T  G=$G

#.....  define Podman image, later is the default
export PODMANHPC_ADDITIONAL_STORES=/dvs_ro/cfs/cdirs/nintern/gzquse/podman_common/
IMG=gzquse/cudaquanmpi-qiskit:p6
# export PODMANHPC_ADDITIONAL_STORES=/global/cfs/cdirs/nstaff/balewski/podman_common/
# IMG=balewski/cudaquanmpi-qiskit:p7
echo S: head:`hostname`  use image $IMG

#..... input data:
if [ "$USER" == "balewski" ]; then  #Jan
    CFSH=/global/cfs/cdirs/mpccc/balewski
    #BASE_PATH=${CFSH}/quantDataVault2024/dataCudaQ_june28 - good campaign
    BASE_PATH=${CFSH}/quantDataVault2024/dataCudaQ_July9
    DATA_SRC=${CFSH}/2024_martin_gradient
elif [ "$USER" == "gzquse" ]; then    # Martin
    CFSH=/pscratch/sd/g/gzquse
    # remember to change this line
    BASE_PATH=${CFSH}/quantDataVault2024/dataCudaQ_July8
    DATA_SRC=${CFSH}/GRADIENT_IMAGE
fi

#...  sandbox code
jobId=${SLURM_JOBID:27658327}
wrkPath=$SCRATCH/jobs_cudaq/$jobId

echo wrkPath=$wrkPath
mkdir -p $wrkPath
cp -rp ../toolbox distributed *py  wrapPodman.sh batchPodman.slr $wrkPath/
cd $wrkPath

# .... task to be executed by Podman
# CPU version uses srun  for mutiple tasks
CMD=" python3 -u  ./run_gateList.py  --expName $expN --backend $backend   --numShots $shots  --basePath /myData  "

if [ "$trg" == "adj-gpu" ]; then
    # is neede for nq=33 or 34 
     CMD=" mpiexec -np 4 "$CMD
fi

CMD1="  ./simple_ghzV2_cudaq.py   --numShots 10 --cudaqTarget nvidia-mqpu  --numRepeat 50  --numQubits 28 " # 1 GPU
CMD2=" mpirun -np 4 python3  ./simple_ghzV2_cudaq.py  --numShots 10 --cudaqTarget nvidia-mgpu --numRepeat 50 --numQubits 30 "  # 4 adj-GPU

CMD3="mpirun -np 4 python3 ./simple_ghzV2_cudaq.py --numShots 10200 --cudaqTarget nvidia-mgpu --numRepeat 3600 --numQubits 29 "  # 4 adj-GPU  100k-CX match to ` 

# spare: 
#pwd
#ls
#nvidia-smi

if [ "$trg" != "par-cpu" ]; then
    echo S:  warmup GPUs with short 4-GPU job
    ./wrapPodman.sh $IMG " $CMD2 " $wrkPath  $BASE_PATH
fi
#CMD=$CMD3  # testing
echo "S:..... fire the task ...."
echo S: CMD=$CMD
srun -l -n $G ./wrapPodman.sh $IMG " $CMD " $wrkPath  $BASE_PATH
echo S:done ; date 

#Cancel all my jobs:
#  squeue -u $USER -h | awk '{print $1}' | xargs scancel

# all jobs in the qos
#  squeue --qos=gpu_shared -o "%.7i %.10P %.12j %.8u %.2t %.10M %.6D %R %.20N"

