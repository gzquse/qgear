{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConcatenate and plot selected metrics from multiple jobs.\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| default_exp plotter\n",
    "\"\"\"\n",
    "Concatenate and plot selected metrics from multiple jobs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1afb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, numpy as np\n",
    "from qgear.toolbox.PlotterBackbone import PlotterBackbone\n",
    "from qgear.toolbox.Util_IOfunc import read_yaml\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from qgear.toolbox.Util_H5io4 import write4_data_hdf5, read4_data_hdf5\n",
    "from qgear.toolbox.Util_ibm import marginalize_qcrank_EV\n",
    "from qgear.toolbox.Util_Qiskit import unpack_numpy_to_counts\n",
    "from qgear.toolbox.PlotterQCrank import Plotter\n",
    "\n",
    "def extract_date_from_path(file_path):\n",
    "    \"Extract date from a path containing 'dataCudaQ_<DATE>'\"\n",
    "    for component in file_path.split('/'):\n",
    "        if component.startswith('dataCudaQ_'):\n",
    "            return component[len('dataCudaQ_'):]\n",
    "    return None\n",
    "\n",
    "def extract_qft_from_filename(filename):\n",
    "    \"Check if filename contains 'qft1' and return it if found\"\n",
    "    for component in filename.split('_'):\n",
    "        if component == \"qft1\":\n",
    "            return component\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a83eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def readOne(inpF, dataD, verb=1):\n",
    "    \"Read one YAML metrics file (non-QFT)\"\n",
    "    assert os.path.exists(inpF)\n",
    "    date = extract_date_from_path(inpF)\n",
    "    xMD = read_yaml(inpF, verb)\n",
    "    nq = float(xMD['num_qubit'])\n",
    "    runt = float(xMD['elapsed_time']) / float(xMD['num_circ'])\n",
    "    cores = xMD.get('cores', 32)\n",
    "    tasks_per_node = xMD.get('tasks_per_node', 4)\n",
    "    tag1 = 'cpu' if 'cpu_info' in xMD else 'gpu'\n",
    "    tag2 = xMD['target']\n",
    "    if tag1 not in dataD:\n",
    "        dataD[tag1] = {}\n",
    "    num_cx_formatted = \"10k\" if xMD[\"num_cx\"] == 10000 else f'{xMD[\"num_cx\"]}'\n",
    "    if tag1 == 'cpu':\n",
    "        tag3 = f'{num_cx_formatted}CX_c{cores}_tp{tasks_per_node}'\n",
    "    else:\n",
    "        g_tag = tag2.split('-')[1] if '-' in tag2 else 'gpu'\n",
    "        tag3 = f'{g_tag}.{num_cx_formatted}CX'\n",
    "    if tag2 not in dataD[tag1]:\n",
    "        dataD[tag1][tag2] = {}\n",
    "    if tag3 not in dataD[tag1][tag2]:\n",
    "        dataD[tag1][tag2][tag3] = {'nq': [], 'runt': [], 'cores': [], 'tasks_per_node': [], 'date': []}\n",
    "    head = dataD[tag1][tag2][tag3]\n",
    "    head['nq'].append(nq)\n",
    "    head['runt'].append(runt)\n",
    "    head['cores'].append(cores)\n",
    "    head['tasks_per_node'].append(tasks_per_node)\n",
    "    head['date'].append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff00f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def readOneQFT(inpF, dataD, qft, verb=1):\n",
    "    \"Read one YAML metrics file for QFT runs\"\n",
    "    assert os.path.exists(inpF)\n",
    "    date = extract_date_from_path(inpF)\n",
    "    xMD = read_yaml(inpF, verb)\n",
    "    nq = float(xMD['num_qubit'])\n",
    "    runt = float(xMD['elapsed_time'])\n",
    "    tag1 = qft\n",
    "    tag2 = xMD['target']\n",
    "    if tag1 not in dataD:\n",
    "        dataD[tag1] = {}\n",
    "    num_shots_formatted = \"10k\" if xMD[\"num_shots\"] == 10000 else xMD[\"num_shots\"]\n",
    "    options = inpF.split('/')[-1].split('_')[-2]\n",
    "    g_tag = tag2.split('-')[1] if '-' in tag2 else 'gpu'\n",
    "    tag3 = f'{qft}.{g_tag}.{options}.{num_shots_formatted}S'\n",
    "    if tag2 not in dataD[tag1]:\n",
    "        dataD[tag1][tag2] = {}\n",
    "    if tag3 not in dataD[tag1][tag2]:\n",
    "        dataD[tag1][tag2][tag3] = {'nq': [], 'runt': [], 'shots': [], 'date': []}\n",
    "    head = dataD[tag1][tag2][tag3]\n",
    "    head['nq'].append(nq)\n",
    "    head['runt'].append(runt)\n",
    "    head['shots'].append(xMD['num_shots'])\n",
    "    head['date'].append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def find_yaml_files(directory_path, vetoL=None):\n",
    "    \"Find all .yaml files in a directory, excluding files with veto strings\"\n",
    "    if vetoL is None:\n",
    "        vetoL = []\n",
    "    yaml_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.yaml') and not any(veto in file for veto in vetoL):\n",
    "                yaml_files.append(os.path.join(root, file))\n",
    "    return yaml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66864aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sort_end_lists(d, sort_key='nq', val_key='runt', parent_key=''):\n",
    "    \"Recursively sort lists in nested dicts by a sort_key\"\n",
    "    if sort_key in d:\n",
    "        xV, yV = d[sort_key], d[val_key]\n",
    "        xU, yU = map(list, zip(*sorted(zip(xV, yV), key=lambda x: x[0])))\n",
    "        d[sort_key] = np.array(xU)\n",
    "        d[val_key] = np.array(yU)\n",
    "        return\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            sort_end_lists(v, sort_key, val_key, f\"{parent_key}.{k}\" if parent_key else k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MetricsPlotter(PlotterBackbone):\n",
    "    \"Plotter for concatenated metrics\"\n",
    "    def __init__(self, prjName='metrics', shift=True, outPath='out', noXterm=True, verb=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prjName: Project name for plots\n",
    "            shift: Whether to shift CPU points to avoid overlap\n",
    "            outPath: Output directory for plots\n",
    "            noXterm: Disable X-term (for headless plotting)\n",
    "            verb: Verbosity level\n",
    "        \"\"\"\n",
    "        from types import SimpleNamespace\n",
    "        args = SimpleNamespace(\n",
    "            prjName=prjName,\n",
    "            shift=shift,\n",
    "            outPath=outPath,\n",
    "            noXterm=noXterm,\n",
    "            verb=verb\n",
    "        )\n",
    "        super().__init__(args)\n",
    "\n",
    "    def compute_time(self, bigD, tag1, figId=1, shift=False):\n",
    "        import numpy as np\n",
    "        nrow, ncol = 1, 1\n",
    "        figId = self.smart_append(figId)\n",
    "        fig = self.plt.figure(figId, facecolor='white', figsize=(5.5, 7))\n",
    "        ax = self.plt.subplot(nrow, ncol, 1)\n",
    "\n",
    "        if 'gpu' in tag1:\n",
    "            dataD = bigD[tag1.split('-')[1]]\n",
    "        elif 'qft' in tag1:\n",
    "            dataD = bigD[tag1]\n",
    "        else:\n",
    "            dataD = bigD[tag1]\n",
    "\n",
    "        for tag2 in dataD:\n",
    "            for tag3 in dataD[tag2]:\n",
    "                if '20000CX' in tag3:\n",
    "                    continue\n",
    "                dataE = dataD[tag2][tag3]\n",
    "                nqV = dataE['nq']\n",
    "                runtV = dataE['runt'] / 60.0\n",
    "                dLab = f'{tag3}'\n",
    "                dCol = 'k'\n",
    "                marker_style = 'o'\n",
    "\n",
    "                if shift and tag1 == 'cpu':\n",
    "                    shift_x = np.random.uniform(-0.1, 0.1, size=len(nqV))\n",
    "                    shift_y = np.random.uniform(-0.1, 0.1, size=len(runtV))\n",
    "                    ax.plot(nqV + shift_x, runtV + shift_y, marker=marker_style,\n",
    "                            linestyle='-', color=dCol, label=dLab, markersize=9)\n",
    "                else:\n",
    "                    ax.plot(nqV, runtV, marker=marker_style, linestyle='-',\n",
    "                            color=dCol, label=dLab, markersize=9)\n",
    "\n",
    "        ax.set(xlabel='num qubits', ylabel='compute end-state (minutes)')\n",
    "        ax.set_title(f'Compute state-vector tag1={tag1}', pad=50)\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(1e-3, 1e+0)\n",
    "        ax.set_xlim(15.5, 33.5)\n",
    "        ax.grid()\n",
    "        ax.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                  ncol=3, mode=\"expand\", borderaxespad=0., fontsize=8.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cea0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def metrics_plot(\n",
    "    measPath: str = None,\n",
    "    pathL=None,\n",
    "    vetoL=None,\n",
    "    showPlots='b',\n",
    "    shift=True,\n",
    "    outPath='out',\n",
    "    noXterm=True,\n",
    "    verb=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Concatenate and plot metrics from multiple job YAML files.\n",
    "\n",
    "    Args:\n",
    "        corePath: Base path to data folders. Defaults to the current working directory.\n",
    "        pathL: List of date folder suffixes (e.g., ['Nov15']). If None, auto-detects all `dataCudaQ_*` folders.\n",
    "        vetoL: List of substrings to exclude from filenames.\n",
    "        showPlots: String of plots to show ('a'=cpu, 'b'=par-gpu, 'c'=adj-gpu, 'd'=qft).\n",
    "        shift: Whether to randomly shift CPU points to avoid overlap.\n",
    "        outPath: Output directory for plots.\n",
    "        noXterm: Disable X-term (for headless plotting).\n",
    "        verb: Verbosity level.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if measPath is None:\n",
    "        measPath = os.path.join(os.getcwd(), \"meas\")\n",
    "    if vetoL is None:\n",
    "        vetoL = []\n",
    "\n",
    "    if not os.path.isdir(measPath):\n",
    "        raise FileNotFoundError(f\"Metrics directory not found: {measPath}\")\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(outPath, exist_ok=True)\n",
    "    # --- Scan meas directory for YAML files ---\n",
    "    fileL = find_yaml_files(measPath, vetoL)\n",
    "    if not fileL:\n",
    "        raise FileNotFoundError(f\"No YAML files found in {measPath}\")\n",
    "\n",
    "    dataAll, dataQFT = {}, {}\n",
    "    for fileN in fileL:\n",
    "        qft = extract_qft_from_filename(fileN)\n",
    "        if not qft:\n",
    "            readOne(fileN, dataAll)\n",
    "        else:\n",
    "            readOneQFT(fileN, dataQFT, qft)\n",
    "\n",
    "    sort_end_lists(dataAll)\n",
    "    sort_end_lists(dataQFT)\n",
    "\n",
    "    plot = MetricsPlotter(prjName='metrics', shift=shift, outPath=outPath, noXterm=noXterm, verb=verb)\n",
    "    if 'a' in showPlots:\n",
    "        plot.compute_time(dataAll, 'cpu', figId=1, shift=shift)\n",
    "    if 'b' in showPlots:\n",
    "        plot.compute_time(dataAll, 'par-gpu', figId=2, shift=shift)\n",
    "    if 'c' in showPlots:\n",
    "        plot.compute_time(dataAll, 'adj-gpu', figId=3, shift=shift)\n",
    "    if 'd' in showPlots:\n",
    "        plot.compute_time(dataQFT, 'qft', figId=4, shift=shift)\n",
    "    plot.display_all(png=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c561e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\"\"\"\n",
    "Post-processing and plotting for QCrank experiments.\n",
    "\"\"\"\n",
    "# ----------------------------\n",
    "def postproc_qcrank(expD, md, verb=1):\n",
    "    \"\"\"\n",
    "    Post-process QCrank experiment results to reconstruct user data.\n",
    "\n",
    "    Args:\n",
    "        expD: Experiment data dictionary from HDF5.\n",
    "        md: Metadata dictionary from HDF5.\n",
    "        verb: Verbosity level.\n",
    "    \"\"\"\n",
    "    pmd = md['payload']\n",
    "    nq_addr = pmd['nq_addr']\n",
    "    nq_data = pmd['nq_fdata']\n",
    "    seq_len = pmd['seq_len']\n",
    "    nImg = pmd['num_sample']\n",
    "\n",
    "    countsL = unpack_numpy_to_counts(md, expD)\n",
    "\n",
    "    rec_udata = np.zeros((nImg, nq_data, seq_len))  # reconstructed user data\n",
    "    addrBitsL = [nq_data + i for i in range(nq_addr)]\n",
    "\n",
    "    if verb:\n",
    "        print('rec_udata:', rec_udata.shape, 'addrBitsL:', addrBitsL)\n",
    "\n",
    "    T0 = time()\n",
    "    for ic in range(nImg):\n",
    "        counts = countsL[ic]\n",
    "        for ibit in range(nq_data):\n",
    "            T1 = time()\n",
    "            rec_udata[ic, ibit] = marginalize_qcrank_EV(addrBitsL, counts, dataBit=ibit)\n",
    "            if ic < 5 and verb:\n",
    "                print(f\"ic={ic} marginal ibit={ibit} done, elaT={(T1-T0)/60:.1f} min\")\n",
    "\n",
    "    expD['rec_udata'] = rec_udata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ----------------------------\n",
    "def restore_canned_image(expD, md):\n",
    "    \"\"\"\n",
    "    Restore reconstructed image from QCrank output.\n",
    "\n",
    "    Args:\n",
    "        expD: Experiment data dictionary.\n",
    "        md: Metadata dictionary.\n",
    "    \"\"\"\n",
    "    cad = md['canned']\n",
    "    n_img = md['payload']['num_sample']\n",
    "    pixX, pixY = cad['image_shape_xy']\n",
    "\n",
    "    assert n_img == 1\n",
    "    recA = expD['rec_udata'][0]\n",
    "    expD['rec_norm_image'] = recA.reshape(pixY, pixX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d651f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# ----------------------------\n",
    "def residual_analysis(expD, md):\n",
    "    \"\"\"\n",
    "    Compute residual statistics between reconstructed and true data.\n",
    "\n",
    "    Args:\n",
    "        expD: Experiment data dictionary.\n",
    "        md: Metadata dictionary.\n",
    "    \"\"\"\n",
    "    rdata = expD['rec_udata'].flatten()\n",
    "    tdata = expD['true_out_udata'].flatten()\n",
    "    res_data = rdata - tdata\n",
    "    mean = np.mean(res_data)\n",
    "    std = np.std(res_data)\n",
    "    N = res_data.shape[0]\n",
    "    se_s = std / np.sqrt(2 * (N - 1))\n",
    "\n",
    "    if 'postproc' not in md:\n",
    "        md['postproc'] = {}\n",
    "    md['postproc'].update({\n",
    "        'res_mean': float(mean),\n",
    "        'res_std': float(std),\n",
    "        'res_SE_s': float(se_s)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "def process_qcrank_experiment(\n",
    "    exp_name,\n",
    "    inp_path=None,\n",
    "    out_path=\"out\",\n",
    "    show_plots=\"a\",\n",
    "    no_xterm=True,\n",
    "    verb=1,\n",
    "    save_plots=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Load, post-process, and optionally plot QCrank experiment results.\n",
    "\n",
    "    Args:\n",
    "        exp_name: Experiment name (without .h5 extension).\n",
    "        inp_path: Path to raw outputs from experiment. Defaults to current working directory.\n",
    "        out_path: Path to save post-processed results.\n",
    "        show_plots: String of plots to show ('a'=accuracy, 'b'=image, 'c'=dynamic range).\n",
    "        no_xterm: Disable X-term for headless plotting.\n",
    "        verb: Verbosity level.\n",
    "        save_plots: If True, save plots to file.\n",
    "\n",
    "    Returns:\n",
    "        (expD, expMD) - processed data and metadata.\n",
    "    \"\"\"\n",
    "    # Default to current working directory if inp_path is not provided\n",
    "    if inp_path is None:\n",
    "        inp_path = os.path.join(os.getcwd(), \"out\")\n",
    "\n",
    "    np.set_printoptions(precision=3)\n",
    "\n",
    "    inpF = exp_name + '.h5'\n",
    "    expD, expMD = read4_data_hdf5(os.path.join(inp_path, inpF))\n",
    "    if verb >= 2:\n",
    "        print('M:expMD:')\n",
    "        pprint(expMD)\n",
    "\n",
    "    postproc_qcrank(expD, expMD, verb=verb)\n",
    "    restore_canned_image(expD, expMD)\n",
    "\n",
    "    # Save post-processed output\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    outF = os.path.join(out_path, expMD['short_name'] + '.post.h5')\n",
    "    write4_data_hdf5(expD, outF, expMD)\n",
    "\n",
    "    # Plotting\n",
    "    expMD['plot'] = {'resid_max_range': 0.4}\n",
    "    args = type(\"Args\", (), {})()\n",
    "    args.prjName = expMD['short_name']\n",
    "    args.noXterm = no_xterm\n",
    "    args.outPath = out_path\n",
    "    args.verb = verb\n",
    "    plot = Plotter(args)\n",
    "\n",
    "    if 'a' in show_plots:\n",
    "        plot.qcrank_accuracy(expD, expMD, figId=1)\n",
    "    if 'b' in show_plots:\n",
    "        plot.canned_image(expD, expMD, figId=2)\n",
    "    if 'c' in show_plots:\n",
    "        plot.dynamic_range(expD, expMD, figId=3)\n",
    "\n",
    "    plot.display_all(png=int(save_plots))\n",
    "    return expD, expMD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
